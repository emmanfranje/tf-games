{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RUN THE FOLLOWING PAG MAGTTRAIN ULET. NO NEED PAG GAME LANG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import CSVLogger, ModelCheckpoint, EarlyStopping\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Activation, Convolution2D, Dropout, Conv2D\n",
    "from keras.layers import AveragePooling2D, BatchNormalization\n",
    "from keras.layers import GlobalAveragePooling2D\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import SeparableConv2D\n",
    "from keras import layers\n",
    "from keras.regularizers import l2\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "INITIALIZE THE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/emmanfranje/Documents/aiaiaiai/env/lib/python3.7/site-packages/ipykernel_launcher.py:16: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "\n",
    " \n",
    "dataset_path = 'fer2013.csv'\n",
    "image_size=(48,48)\n",
    " \n",
    "def load_fer2013():\n",
    "    data = pd.read_csv(dataset_path)\n",
    "    pixels = data['pixels'].tolist()\n",
    "    width, height = 48, 48\n",
    "    faces = []\n",
    "    for pixel_sequence in pixels:\n",
    "        face = [int(pixel) for pixel in pixel_sequence.split(' ')]\n",
    "        face = np.asarray(face).reshape(width, height)\n",
    "        face = cv2.resize(face.astype('uint8'),image_size)\n",
    "        faces.append(face.astype('float32'))\n",
    "    faces = np.asarray(faces)\n",
    "    faces = np.expand_dims(faces, -1)\n",
    "    emotions = pd.get_dummies(data['emotion']).as_matrix()\n",
    "    return faces, emotions\n",
    " \n",
    "def preprocess_input(x, v2=True):\n",
    "    x = x.astype('float32')\n",
    "    x = x / 255.0\n",
    "    if v2:\n",
    "        x = x - 0.5\n",
    "        x = x * 2.0\n",
    "    return x\n",
    " \n",
    "faces, emotions = load_fer2013()\n",
    "faces = preprocess_input(faces)\n",
    "xtrain, xtest,ytrain,ytest = train_test_split(faces, emotions,test_size=0.2,shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            (None, 48, 48, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 46, 46, 8)    72          input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 46, 46, 8)    32          conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 46, 46, 8)    0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 44, 44, 8)    576         activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 44, 44, 8)    32          conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 44, 44, 8)    0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_25 (SeparableC (None, 44, 44, 16)   200         activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 44, 44, 16)   64          separable_conv2d_25[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 44, 44, 16)   0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_26 (SeparableC (None, 44, 44, 16)   400         activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 44, 44, 16)   64          separable_conv2d_26[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 22, 22, 16)   128         activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling2D) (None, 22, 22, 16)   0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 22, 22, 16)   64          conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 22, 22, 16)   0           max_pooling2d_13[0][0]           \n",
      "                                                                 batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_27 (SeparableC (None, 22, 22, 32)   656         add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 22, 22, 32)   128         separable_conv2d_27[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 22, 22, 32)   0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_28 (SeparableC (None, 22, 22, 32)   1312        activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 22, 22, 32)   128         separable_conv2d_28[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 11, 11, 32)   512         add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling2D) (None, 11, 11, 32)   0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 11, 11, 32)   128         conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 11, 11, 32)   0           max_pooling2d_14[0][0]           \n",
      "                                                                 batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_29 (SeparableC (None, 11, 11, 64)   2336        add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 11, 11, 64)   256         separable_conv2d_29[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 11, 11, 64)   0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_30 (SeparableC (None, 11, 11, 64)   4672        activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 11, 11, 64)   256         separable_conv2d_30[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 6, 6, 64)     2048        add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling2D) (None, 6, 6, 64)     0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 6, 6, 64)     256         conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 6, 6, 64)     0           max_pooling2d_15[0][0]           \n",
      "                                                                 batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_31 (SeparableC (None, 6, 6, 128)    8768        add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 6, 6, 128)    512         separable_conv2d_31[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 6, 6, 128)    0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_32 (SeparableC (None, 6, 6, 128)    17536       activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 6, 6, 128)    512         separable_conv2d_32[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 3, 3, 128)    8192        add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling2D) (None, 3, 3, 128)    0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 3, 3, 128)    512         conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 3, 3, 128)    0           max_pooling2d_16[0][0]           \n",
      "                                                                 batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 3, 3, 7)      8071        add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_4 (Glo (None, 7)            0           conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "predictions (Activation)        (None, 7)            0           global_average_pooling2d_4[0][0] \n",
      "==================================================================================================\n",
      "Total params: 58,423\n",
      "Trainable params: 56,951\n",
      "Non-trainable params: 1,472\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "898/897 [==============================] - 118s 132ms/step - loss: 1.7468 - acc: 0.3403 - val_loss: 1.6092 - val_acc: 0.3966\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.60923, saving model to models/_mini_XCEPTION.01-0.40.hdf5\n",
      "Epoch 2/10\n",
      "898/897 [==============================] - 126s 140ms/step - loss: 1.5018 - acc: 0.4389 - val_loss: 1.5090 - val_acc: 0.4465\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.60923 to 1.50902, saving model to models/_mini_XCEPTION.02-0.45.hdf5\n",
      "Epoch 3/10\n",
      "898/897 [==============================] - 125s 139ms/step - loss: 1.3741 - acc: 0.4831 - val_loss: 1.4513 - val_acc: 0.4638\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.50902 to 1.45132, saving model to models/_mini_XCEPTION.03-0.46.hdf5\n",
      "Epoch 4/10\n",
      "898/897 [==============================] - 121s 135ms/step - loss: 1.3077 - acc: 0.5098 - val_loss: 1.3626 - val_acc: 0.4961\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.45132 to 1.36257, saving model to models/_mini_XCEPTION.04-0.50.hdf5\n",
      "Epoch 5/10\n",
      "898/897 [==============================] - 116s 129ms/step - loss: 1.2652 - acc: 0.5290 - val_loss: 1.2599 - val_acc: 0.5341\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.36257 to 1.25989, saving model to models/_mini_XCEPTION.05-0.53.hdf5\n",
      "Epoch 6/10\n",
      "898/897 [==============================] - 117s 130ms/step - loss: 1.2357 - acc: 0.5326 - val_loss: 1.3829 - val_acc: 0.4851\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.25989\n",
      "Epoch 7/10\n",
      "898/897 [==============================] - 119s 132ms/step - loss: 1.2060 - acc: 0.5439 - val_loss: 1.2370 - val_acc: 0.5440\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.25989 to 1.23695, saving model to models/_mini_XCEPTION.07-0.54.hdf5\n",
      "Epoch 8/10\n",
      "898/897 [==============================] - 119s 132ms/step - loss: 1.1838 - acc: 0.5568 - val_loss: 1.1852 - val_acc: 0.5635\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.23695 to 1.18521, saving model to models/_mini_XCEPTION.08-0.56.hdf5\n",
      "Epoch 9/10\n",
      "898/897 [==============================] - 119s 132ms/step - loss: 1.1638 - acc: 0.5632 - val_loss: 1.2518 - val_acc: 0.5433\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.18521\n",
      "Epoch 10/10\n",
      "898/897 [==============================] - 119s 132ms/step - loss: 1.1487 - acc: 0.5676 - val_loss: 1.2491 - val_acc: 0.5453\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.18521\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f88a0b98048>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# parameters\n",
    "batch_size = 32\n",
    "num_epochs = 10\n",
    "input_shape = (48, 48, 1)\n",
    "verbose = 1\n",
    "num_classes = 7\n",
    "patience = 50\n",
    "base_path = 'models/'\n",
    "l2_regularization=0.01\n",
    " \n",
    "# data generator\n",
    "data_generator = ImageDataGenerator(\n",
    "                        featurewise_center=False,\n",
    "                        featurewise_std_normalization=False,\n",
    "                        rotation_range=10,\n",
    "                        width_shift_range=0.1,\n",
    "                        height_shift_range=0.1,\n",
    "                        zoom_range=.1,\n",
    "                        horizontal_flip=True)\n",
    " \n",
    "# model parameters\n",
    "regularization = l2(l2_regularization)\n",
    " \n",
    "# base\n",
    "img_input = Input(input_shape)\n",
    "x = Conv2D(8, (3, 3), strides=(1, 1), kernel_regularizer=regularization, use_bias=False)(img_input)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Conv2D(8, (3, 3), strides=(1, 1), kernel_regularizer=regularization, use_bias=False)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    " \n",
    "# module 1\n",
    "residual = Conv2D(16, (1, 1), strides=(2, 2), padding='same', use_bias=False)(x)\n",
    "residual = BatchNormalization()(residual)\n",
    "x = SeparableConv2D(16, (3, 3), padding='same', kernel_regularizer=regularization, use_bias=False)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = SeparableConv2D(16, (3, 3), padding='same', kernel_regularizer=regularization, use_bias=False)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n",
    "x = layers.add([x, residual])\n",
    " \n",
    "# module 2\n",
    "residual = Conv2D(32, (1, 1), strides=(2, 2), padding='same', use_bias=False)(x)\n",
    "residual = BatchNormalization()(residual)\n",
    "x = SeparableConv2D(32, (3, 3), padding='same', kernel_regularizer=regularization, use_bias=False)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = SeparableConv2D(32, (3, 3), padding='same', kernel_regularizer=regularization, use_bias=False)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n",
    "x = layers.add([x, residual])\n",
    " \n",
    "# module 3\n",
    "residual = Conv2D(64, (1, 1), strides=(2, 2),padding='same', use_bias=False)(x)\n",
    "residual = BatchNormalization()(residual)\n",
    "x = SeparableConv2D(64, (3, 3), padding='same',kernel_regularizer=regularization,use_bias=False)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = SeparableConv2D(64, (3, 3), padding='same',kernel_regularizer=regularization,use_bias=False)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n",
    "x = layers.add([x, residual])\n",
    " \n",
    "# module 4\n",
    "residual = Conv2D(128, (1, 1), strides=(2, 2),padding='same', use_bias=False)(x)\n",
    "residual = BatchNormalization()(residual)\n",
    "x = SeparableConv2D(128, (3, 3), padding='same',kernel_regularizer=regularization,use_bias=False)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = SeparableConv2D(128, (3, 3), padding='same',kernel_regularizer=regularization,use_bias=False)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n",
    "x = layers.add([x, residual])\n",
    "x = Conv2D(num_classes, (3, 3), padding='same')(x)\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "output = Activation('softmax',name='predictions')(x)\n",
    " \n",
    "model = Model(img_input, output)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "model.summary()\n",
    " \n",
    "# callbacks\n",
    "log_file_path = base_path + '_emotion_training.log'\n",
    "csv_logger = CSVLogger(log_file_path, append=False)\n",
    "early_stop = EarlyStopping('val_loss', patience=patience)\n",
    "reduce_lr = ReduceLROnPlateau('val_loss', factor=0.1, patience=int(patience/4), verbose=1)\n",
    "trained_models_path = base_path + '_mini_XCEPTION'\n",
    "model_names = trained_models_path + '.{epoch:02d}-{val_acc:.2f}.hdf5'\n",
    "model_checkpoint = ModelCheckpoint(model_names, 'val_loss', verbose=1,save_best_only=True)\n",
    "callbacks = [model_checkpoint, csv_logger, early_stop, reduce_lr]\n",
    " \n",
    "model.fit_generator(data_generator.flow(xtrain, ytrain,batch_size),\n",
    "                        steps_per_epoch=len(xtrain) / batch_size,\n",
    "                        epochs=num_epochs, verbose=1, callbacks=callbacks,\n",
    "                        validation_data=(xtest,ytest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TEST OPENCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0806 15:48:56.144783 140474093037184 deprecation_wrapper.py:119] From /home/emmanfranje/Documents/aiaiaiai/env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0806 15:48:56.317464 140474093037184 deprecation_wrapper.py:119] From /home/emmanfranje/Documents/aiaiaiai/env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0806 15:48:56.450374 140474093037184 deprecation_wrapper.py:119] From /home/emmanfranje/Documents/aiaiaiai/env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:245: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0806 15:48:56.452020 140474093037184 deprecation_wrapper.py:119] From /home/emmanfranje/Documents/aiaiaiai/env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W0806 15:48:56.453712 140474093037184 deprecation_wrapper.py:119] From /home/emmanfranje/Documents/aiaiaiai/env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "W0806 15:48:57.729313 140474093037184 deprecation_wrapper.py:119] From /home/emmanfranje/Documents/aiaiaiai/env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "W0806 15:48:58.284814 140474093037184 deprecation_wrapper.py:119] From /home/emmanfranje/Documents/aiaiaiai/env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'preds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-ac732888997e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0memotion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEMOTIONS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m                 \u001b[0;31m# construct the label text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m                 \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"{}: {:.2f}%\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memotion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprob\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'preds' is not defined"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import img_to_array\n",
    "import imutils\n",
    "import cv2\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "\n",
    "# parameters for loading data and images\n",
    "detection_model_path = 'haarcascade_frontalface_default.xml'\n",
    "emotion_model_path = 'models/_mini_XCEPTION.08-0.56.hdf5'\n",
    "\n",
    "# hyper-parameters for bounding boxes shape\n",
    "# loading models\n",
    "face_detection = cv2.CascadeClassifier(detection_model_path)\n",
    "emotion_classifier = load_model(emotion_model_path, compile=False)\n",
    "EMOTIONS = [\"angry\" ,\"disgust\",\"scared\", \"happy\", \"sad\", \"surprised\",\n",
    " \"neutral\"]\n",
    "\n",
    "\n",
    "# starting video streaming\n",
    "cv2.namedWindow('your_face')\n",
    "camera = cv2.VideoCapture(0)\n",
    "while True:\n",
    "    frame = camera.read()[1]\n",
    "    #reading the frame\n",
    "    frame = imutils.resize(frame,width=400)\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_detection.detectMultiScale(gray,scaleFactor=1.1,minNeighbors=5,minSize=(30,30),flags=cv2.CASCADE_SCALE_IMAGE)\n",
    "    \n",
    "    canvas = np.zeros((250, 300, 3), dtype=\"uint8\")\n",
    "    frameClone = frame.copy()\n",
    "    if len(faces) > 0:\n",
    "        faces = sorted(faces, reverse=True,\n",
    "        key=lambda x: (x[2] - x[0]) * (x[3] - x[1]))[0]\n",
    "        (fX, fY, fW, fH) = faces\n",
    "                    # Extract the ROI of the face from the grayscale image, resize it to a fixed 48x48 pixels, and then prepare\n",
    "            # the ROI for classification via the CNN\n",
    "        roi = gray[fY:fY + fH, fX:fX + fW]\n",
    "        roi = cv2.resize(roi, (48, 48))\n",
    "        roi = roi.astype(\"float\") / 255.0\n",
    "        roi = img_to_array(roi)\n",
    "        roi = np.expand_dims(roi, axis=0)\n",
    "        \n",
    "        \n",
    "        preds = emotion_classifier.predict(roi)[0]\n",
    "        emotion_probability = np.max(preds)\n",
    "        label = EMOTIONS[preds.argmax()]\n",
    "        #if label == 'happy':\n",
    "            #print('happy')\n",
    "            #IT WORKS\n",
    "\n",
    " \n",
    "    for (i, (emotion, prob)) in enumerate(zip(EMOTIONS, preds)):\n",
    "                # construct the label text\n",
    "                text = \"{}: {:.2f}%\".format(emotion, prob * 100)\n",
    "                w = int(prob * 300)\n",
    "                cv2.rectangle(canvas, (7, (i * 35) + 5),\n",
    "                (w, (i * 35) + 35), (0, 0, 255), -1)\n",
    "                cv2.putText(canvas, text, (10, (i * 35) + 23),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.45,\n",
    "                (255, 255, 255), 2)\n",
    "                cv2.putText(frameClone, label, (fX, fY - 10),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.45, (0, 0, 255), 2)\n",
    "                cv2.rectangle(frameClone, (fX, fY), (fX + fW, fY + fH),\n",
    "                              (0, 0, 255), 2)\n",
    "\n",
    "    cv2.imshow('your_face', frameClone)\n",
    "    cv2.imshow(\"Probabilities\", canvas)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "camera.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RUN THIS TO PLAY THE GAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0806 16:22:37.902565 140078402807424 deprecation_wrapper.py:119] From /home/emmanfranje/Documents/aiaiaiai/env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0806 16:22:37.925488 140078402807424 deprecation_wrapper.py:119] From /home/emmanfranje/Documents/aiaiaiai/env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0806 16:22:37.953418 140078402807424 deprecation_wrapper.py:119] From /home/emmanfranje/Documents/aiaiaiai/env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:245: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0806 16:22:37.954409 140078402807424 deprecation_wrapper.py:119] From /home/emmanfranje/Documents/aiaiaiai/env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W0806 16:22:37.955472 140078402807424 deprecation_wrapper.py:119] From /home/emmanfranje/Documents/aiaiaiai/env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 1.9.6\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0806 16:22:38.035337 140078402807424 deprecation_wrapper.py:119] From /home/emmanfranje/Documents/aiaiaiai/env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "W0806 16:22:38.349682 140078402807424 deprecation_wrapper.py:119] From /home/emmanfranje/Documents/aiaiaiai/env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import img_to_array\n",
    "import imutils\n",
    "import cv2\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "\n",
    "import pygame\n",
    "import random\n",
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# parameters for loading data and images\n",
    "detection_model_path = 'haarcascade_frontalface_default.xml'\n",
    "emotion_model_path = 'models/_mini_XCEPTION.08-0.56.hdf5'\n",
    "facecasc = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "# loading models\n",
    "face_detection = cv2.CascadeClassifier(detection_model_path)\n",
    "emotion_classifier = load_model(emotion_model_path, compile=False)\n",
    "EMOTIONS = [\"angry\" ,\"disgust\",\"scared\", \"happy\", \"sad\", \"surprised\",\n",
    " \"neutral\"]\n",
    "\n",
    "# Define some colors\n",
    "BLACK = (0, 0, 0)\n",
    "WHITE = (255, 255, 255)\n",
    "GRAY = (159, 163, 168)\n",
    "GREEN = (0, 255, 0)\n",
    "RED = (255, 0, 0)\n",
    "CAR_COLOR = (0, 230, 0)\n",
    "TEXT_COLOR = (250, 105, 10)\n",
    "\n",
    "\n",
    "\n",
    "pygame.init()\n",
    "\n",
    "\n",
    "class Car:\n",
    "    def __init__(self, x=0, y=0, dx=4, dy=0, width=30, height=30, color=RED):\n",
    "        self.image = \"\"\n",
    "        self.x = x\n",
    "\n",
    "        self.y = y\n",
    "        self. dx = dx\n",
    "        self.dy = dy\n",
    "        self.width = width\n",
    "        self.height = height\n",
    "        self.color = color\n",
    "\n",
    "    def load_image(self, img):\n",
    "        self.image = pygame.image.load(img).convert()\n",
    "        self.image.set_colorkey(BLACK)\n",
    "\n",
    "    def draw_image(self):\n",
    "        screen.blit(self.image, [self.x, self.y])\n",
    "\n",
    "    def move_x(self):\n",
    "        self.x += self.dx\n",
    "\n",
    "    def move_y(self):\n",
    "        self.y += self.dy\n",
    "\n",
    "    def draw_rect(self):\n",
    "        pygame.draw.rect(screen, self.color, [self.x, self.y, self.width, self.height], 0)\n",
    "\n",
    "    def check_out_of_screen(self):\n",
    "        if self.x+self.width > 400 or self.x < 0:\n",
    "            self.x -= self.dx\n",
    "\n",
    "\n",
    "def check_collision(player_x, player_y, player_width, player_height, car_x, car_y, car_width, car_height):\n",
    "    if (player_x+player_width > car_x) and (player_x < car_x+car_width) and (player_y < car_y+car_height) and (player_y+player_height > car_y):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "\n",
    "# Set the width and height of the screen [width, height]\n",
    "size = (400, 700)\n",
    "screen = pygame.display.set_mode(size)\n",
    "\n",
    "pygame.display.set_caption(\"Ride the Road\")\n",
    "\n",
    "# Loop until the user clicks the close button.\n",
    "done = False\n",
    "\n",
    "# Used to manage how fast the screen updates\n",
    "clock = pygame.time.Clock()\n",
    "\n",
    "# Create a player car object\n",
    "player = Car(175, 475, 0, 0, 70, 131, RED)\n",
    "player.load_image(\"player.png\")\n",
    "\n",
    "collision = True\n",
    "\n",
    "# Store the score\n",
    "score = 0\n",
    "\n",
    "# Load the fonts\n",
    "font_40 = pygame.font.SysFont(\"Arial\", 40, True, False)\n",
    "font_30 = pygame.font.SysFont(\"Arial\", 30, True, False)\n",
    "text_title = font_40.render(\"TRANSITFLIX\", True, TEXT_COLOR)\n",
    "#text_right = font_15.render(\"Smile to go right\", True, TEXT_COLOR)\n",
    "#text_left = font_15.render(\"Frown to go left\", True, TEXT_COLOR)\n",
    "text_ins = font_30.render(\"Click to Play!\", True, TEXT_COLOR)\n",
    "\n",
    "\n",
    "def draw_main_menu():\n",
    "    screen.blit(text_title, [size[0] / 2 - 106, size[1] / 2 - 100])\n",
    "    score_text = font_40.render(\"Score: \" + str(score), True, TEXT_COLOR)\n",
    "    screen.blit(score_text, [size[0] / 2 - 70, size[1] / 2 - 30])\n",
    "    #screen.blit(text_right, [size[0] / 2 - 85, size[1] / 2 + 40])\n",
    "    screen.blit(text_ins, [size[0] / 2 - 85, size[1] / 2 + 40])\n",
    "    pygame.display.flip()\n",
    "\n",
    "\n",
    "# Setup the enemy cars\n",
    "cars = []\n",
    "car_count = 2\n",
    "for i in range(car_count):\n",
    "    x = random.randrange(0, 340)\n",
    "    car = Car(x, random.randrange(-150, -50), 0, random.randint(5, 10), 60, 60, CAR_COLOR)\n",
    "    cars.append(car)\n",
    "\n",
    "\n",
    "# Setup the stripes.\n",
    "stripes = []\n",
    "stripe_count = 20\n",
    "stripe_x = 185\n",
    "stripe_y = -10\n",
    "stripe_width = 20\n",
    "stripe_height = 80\n",
    "space = 20\n",
    "for i in range(stripe_count):\n",
    "    stripes.append([190, stripe_y])\n",
    "    stripe_y += stripe_height + space\n",
    "\n",
    "# -------- Main Program Loop -----------\n",
    "\n",
    "cv2.namedWindow('your_face')\n",
    "camera = cv2.VideoCapture(0)\n",
    "\n",
    "while not done:\n",
    "\n",
    "#camera here\n",
    "    frame = camera.read()[1]\n",
    "    #reading the frame\n",
    "    frame = imutils.resize(frame,width=400)\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_detection.detectMultiScale(gray,scaleFactor=1.1,minNeighbors=5,minSize=(30,30),flags=cv2.CASCADE_SCALE_IMAGE)\n",
    "    \n",
    "    canvas = np.zeros((250, 300, 3), dtype=\"uint8\")\n",
    "    frameClone = frame.copy()\n",
    "    if len(faces) > 0:\n",
    "        faces = sorted(faces, reverse=True,\n",
    "        key=lambda x: (x[2] - x[0]) * (x[3] - x[1]))[0]\n",
    "        (fX, fY, fW, fH) = faces\n",
    "                    # Extract the ROI of the face from the grayscale image, resize it to a fixed 48x48 pixels, and then prepare\n",
    "            # the ROI for classification via the CNN\n",
    "        roi = gray[fY:fY + fH, fX:fX + fW]\n",
    "        roi = cv2.resize(roi, (48, 48))\n",
    "        roi = roi.astype(\"float\") / 255.0\n",
    "        roi = img_to_array(roi)\n",
    "        roi = np.expand_dims(roi, axis=0)\n",
    "        \n",
    "        \n",
    "        preds = emotion_classifier.predict(roi)[0]\n",
    "        emotion_probability = np.max(preds)\n",
    "        label = EMOTIONS[preds.argmax()]\n",
    "        if label == 'happy':\n",
    "            player.dx = 4\n",
    "            #print('happy')\n",
    "            #IT WORKS\n",
    "        #elif label == 'neutral':\n",
    "        #    player.dx = 0\n",
    "        #elif label == 'angry':\n",
    "        #    player.dx = -4\n",
    "        else:\n",
    "            player.dx = -4\n",
    " \n",
    "    for (i, (emotion, prob)) in enumerate(zip(EMOTIONS, preds)):\n",
    "                # construct the label text\n",
    "                text = \"{}: {:.2f}%\".format(emotion, prob * 100)\n",
    "                w = int(prob * 300)\n",
    "                cv2.rectangle(canvas, (7, (i * 35) + 5),\n",
    "                (w, (i * 35) + 35), (0, 0, 255), -1)\n",
    "                cv2.putText(canvas, text, (10, (i * 35) + 23),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.45,\n",
    "                (255, 255, 255), 2)\n",
    "                cv2.putText(frameClone, label, (fX, fY - 10),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.45, (0, 0, 255), 2)\n",
    "                cv2.rectangle(frameClone, (fX, fY), (fX + fW, fY + fH),\n",
    "                              (0, 0, 255), 2)\n",
    "\n",
    "    cv2.imshow('your_face', frameClone)\n",
    "    cv2.imshow(\"Probabilities\", canvas)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "\n",
    "\n",
    "    # --- Main event loop\n",
    "    for event in pygame.event.get():\n",
    "        if event.type == pygame.QUIT:\n",
    "            done = True\n",
    "\n",
    "        # Reset everything when the user starts the game.\n",
    "        if collision and event.type == pygame.MOUSEBUTTONDOWN:\n",
    "            collision = False\n",
    "            for i in range(car_count):\n",
    "                cars[i].y = random.randrange(-150, -50)\n",
    "                cars[i].x = random.randrange(0, 350)\n",
    "            player.x = 175\n",
    "            player.dx = 0\n",
    "            score = 0\n",
    "            pygame.mouse.set_visible(False)\n",
    "\n",
    "        if not collision:\n",
    "            if event.type == pygame.KEYDOWN:\n",
    "                if event.key == pygame.K_RIGHT:\n",
    "                    player.dx = 4\n",
    "                elif event.key == pygame.K_LEFT:\n",
    "                    player.dx = -4\n",
    "\n",
    "            if event.type == pygame.KEYUP:\n",
    "                if event.key == pygame.K_LEFT:\n",
    "                    player.dx = 0\n",
    "                elif event.key == pygame.K_RIGHT:\n",
    "                    player.dx = 0\n",
    "\n",
    "    # --- Game logic should go here\n",
    "\n",
    "    # --- Screen-clearing code goes here\n",
    "    screen.fill(GRAY)\n",
    "\n",
    "    # --- Drawing code should go here\n",
    "    if not collision:\n",
    "        # Draw the stripes\n",
    "        for i in range(stripe_count):\n",
    "            pygame.draw.rect(screen, WHITE, [stripes[i][0], stripes[i][1], stripe_width, stripe_height])\n",
    "        # Move the stripes\n",
    "        for i in range(stripe_count):\n",
    "            stripes[i][1] += 3\n",
    "            if stripes[i][1] > size[1]:\n",
    "                stripes[i][1] = -40 - stripe_height\n",
    "\n",
    "        player.draw_image()\n",
    "        player.move_x()\n",
    "        player.check_out_of_screen()\n",
    "\n",
    "        # Check if the enemy cars move out of the screen.\n",
    "        for i in range(car_count):\n",
    "            cars[i].draw_rect()\n",
    "            cars[i].y += cars[i].dy\n",
    "            if cars[i].y > size[1]:\n",
    "                score += 10\n",
    "                cars[i].y = random.randrange(-150, -50)\n",
    "                cars[i].x = random.randrange(0, 340)\n",
    "                cars[i].dy = random.randint(4, 9)\n",
    "\n",
    "        # Check the collision of the player with the car\n",
    "        for i in range(car_count):\n",
    "            if check_collision(player.x, player.y, player.width, player.height, cars[i].x, cars[i].y, cars[i].width, cars[i].height):\n",
    "                collision = True\n",
    "                pygame.mouse.set_visible(True)\n",
    "                break\n",
    "\n",
    "        # Draw the score.\n",
    "        txt_score = font_30.render(\"Score: \"+str(score), True, WHITE)\n",
    "        screen.blit(txt_score, [15, 15])\n",
    "\n",
    "        pygame.display.flip()\n",
    "    else:\n",
    "        draw_main_menu()\n",
    "\n",
    "    # --- Limit to 60 frames per second\n",
    "    clock.tick(60)\n",
    "    \n",
    "camera.release()\n",
    "cv2.destroyAllWindows()\n",
    "# Close the window and quit.\n",
    "pygame.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
